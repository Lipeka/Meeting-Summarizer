{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMg25zGCEyXosrEtGu5Es+K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lipeka/Meeting-Summarizer/blob/main/meetsum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "VlbLaK0bAcGF",
        "outputId": "55482ea0-e101-46af-cde4-a955cb4e940a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• How would you like to provide meeting input?\n",
            "1. Paste text manually\n",
            "2. Upload audio file (.mp3 or .wav)\n",
            "Enter 1 or 2: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6503cadd-c688-4904-9f69-435a633f4f0a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6503cadd-c688-4904-9f69-435a633f4f0a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ttsMP3.com_VoiceText_2025-6-10_12-50-11.mp3 to ttsMP3.com_VoiceText_2025-6-10_12-50-11.mp3\n",
            "üéß Transcribing audio using Whisper...\n",
            "\n",
            "üìù Transcribed Text:\n",
            " Good morning everyone, let's get started. First, a quick overview of our quarterly performance, we saw a 12% increase in revenue compared to last quarter, primarily driven by our new enterprise clients in the fintech sector. However, the operations team flagged a rising customer churn rate in our SaaS product line, so Ravi, I'd like you to investigate the retention metrics and propose improvements by next Friday. On that note, Priya from marketing will work closely with you to align messaging and campaign adjustments. Moving on, we've onboarded six new members across departments, please welcome Rajesh in sales, Ananya in data analytics, and the others joining HR and product development. Make sure they're looped into their respective onboarding and buddy sessions. Now, regarding performance, we did a mid-year review, and noticed productivity gaps in the East Region sales team. Sandeep, I'm assigning you to mentor that group and submit a performance improvement roadmap by end of the month. Unfortunately, I also need to share that due to restructuring, we're releasing five contractual roles from the support function. HR will handle individual consultations and exit formalities this week. Please ensure empathy and confidentiality are maintained throughout the process. Lastly, as we prepare for the upcoming product launch, Neha and the dev team will lead sprint planning while the node from QA oversees testing cycles. Weekly progress checkpoints start Monday. Any blockers should be communicated in the central task board. That's all from my side, any questions or updates from your ends?\n",
            "\n",
            "üß† Sending content for summarization...\n",
            "\n",
            "üìã Structured Output:\n",
            "  [\n",
            "  {\n",
            "    \"assigned_to\": \"Ravi\",\n",
            "    \"department\": \"operations\",\n",
            "    \"task_description\": \"Investigate retention metrics and propose improvements for SaaS product line by next Friday.\",\n",
            "    \"deadline\": \"Next Friday\"\n",
            "  },\n",
            "  {\n",
            "    \"assigned_to\": \"Priya\",\n",
            "    \"department\": \"marketing\",\n",
            "    \"task_description\": \"Work closely with Ravi to align messaging and campaign adjustments.\",\n",
            "    \"deadline\": \"Not specified\"\n",
            "  },\n",
            "  {\n",
            "    \"assigned_to\": \"Sandeep\",\n",
            "    \"department\": \"sales\",\n",
            "    \"task_description\": \"Mentor the East Region sales team and submit a performance improvement roadmap by end of the month.\",\n",
            "    \"deadline\": \"End of the month\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# üõ†Ô∏è Install dependencies in Colab\n",
        "!pip install -q pydub SpeechRecognition requests openai-whisper\n",
        "!apt-get -qq install ffmpeg\n",
        "\n",
        "# ‚úÖ Imports\n",
        "import whisper\n",
        "import requests\n",
        "import json\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# üîê OpenRouter API\n",
        "OPENROUTER_API_KEY = \"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\"\n",
        "MODEL = \"mistralai/mistral-7b-instruct:free\"\n",
        "\n",
        "# üîä Whisper transcription\n",
        "def whisper_transcribe(audio_path):\n",
        "    try:\n",
        "        model = whisper.load_model(\"large\")  # You can use \"small\" or \"medium\" for better results\n",
        "        result = model.transcribe(audio_path)\n",
        "        return result[\"text\"]\n",
        "    except Exception as e:\n",
        "        return f\"Whisper error: {str(e)}\"\n",
        "\n",
        "# üß† Summary via OpenRouter\n",
        "def summarize_meeting(input_text):\n",
        "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"HTTP-Referer\": \"https://your-site.com\",\n",
        "        \"X-Title\": \"Meeting Summarizer\",\n",
        "    }\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "From the following meeting transcript, extract only the task assignments.\n",
        "\n",
        "Return a JSON array where each object has:\n",
        "- assigned_to\n",
        "- department\n",
        "- task_description\n",
        "- deadline\n",
        "\n",
        "Do not include general updates, announcements, welcomes, or summaries.\n",
        "Only include actual responsibilities or assignments clearly given to individuals or teams.\n",
        "\n",
        "Meeting Transcript:\n",
        "{input_text}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    payload = {\n",
        "        \"model\": MODEL,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        return result['choices'][0]['message']['content']\n",
        "    else:\n",
        "        return f\"API Error: {response.status_code} - {response.text}\"\n",
        "\n",
        "# üßæ Main function\n",
        "def main():\n",
        "    print(\"üì• How would you like to provide meeting input?\")\n",
        "    print(\"1. Paste text manually\")\n",
        "    print(\"2. Upload audio file (.mp3 or .wav)\")\n",
        "    choice = input(\"Enter 1 or 2: \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        print(\"\\n‚úçÔ∏è Please paste the meeting transcript below. Press Enter when done.\")\n",
        "        print(\"(Type END on a new line to finish)\")\n",
        "        lines = []\n",
        "        while True:\n",
        "            line = input()\n",
        "            if line.strip().upper() == \"END\":\n",
        "                break\n",
        "            lines.append(line)\n",
        "        meeting_text = \"\\n\".join(lines)\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "        audio_path = list(uploaded.keys())[0]\n",
        "\n",
        "        if not (audio_path.endswith(\".wav\") or audio_path.endswith(\".mp3\")):\n",
        "            print(\"‚ùå Please upload a .wav or .mp3 file only.\")\n",
        "            return\n",
        "\n",
        "        # Optional: Convert MP3 to WAV if needed (Whisper supports both)\n",
        "        if audio_path.endswith(\".mp3\"):\n",
        "            sound = AudioSegment.from_mp3(audio_path)\n",
        "            audio_path = audio_path.replace(\".mp3\", \".wav\")\n",
        "            sound.export(audio_path, format=\"wav\")\n",
        "\n",
        "        print(\"üéß Transcribing audio using Whisper...\")\n",
        "        meeting_text = whisper_transcribe(audio_path)\n",
        "        print(f\"\\nüìù Transcribed Text:\\n{meeting_text}\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Invalid choice. Please enter 1 or 2.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nüß† Sending content for summarization...\")\n",
        "    result = summarize_meeting(meeting_text)\n",
        "    print(\"\\nüìã Structured Output:\\n\", result)\n",
        "\n",
        "# ‚úÖ Start the program\n",
        "main()\n"
      ]
    }
  ]
}